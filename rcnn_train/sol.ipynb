{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15f40cdc-f10e-4e65-b906-60ed537bd306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torchvision.transforms import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "880415b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir, transforms=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.transforms = transforms\n",
    "        self.images = os.listdir(image_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def parse_label(self, label_path):\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        with open(label_path, \"r\") as f:\n",
    "            for line in f.readlines():\n",
    "                label, x_min, y_min, x_max, y_max = map(float, line.strip().split())\n",
    "                boxes.append([x_min, y_min, x_max, y_max])\n",
    "                labels.append(int(label))\n",
    "        return boxes, labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = os.path.join(self.image_dir, self.images[idx])\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        # Load label\n",
    "        label_path = os.path.join(\n",
    "            self.label_dir, os.path.splitext(self.images[idx])[0] + \".txt\"\n",
    "        )\n",
    "        boxes, labels = self.parse_label(label_path)\n",
    "\n",
    "        # Convert to tensor\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        # Target dictionary\n",
    "        target = {\"boxes\": boxes, \"labels\": labels}\n",
    "\n",
    "        # Apply transforms\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e83c4c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms\n",
    "def get_transforms():\n",
    "    return torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "train_dataset = CustomDataset(\n",
    "    image_dir=r\"rcnn_train\\dataset_rcnn\\images\\train\",\n",
    "    label_dir=r\"rcnn_train\\dataset_rcnn\\labels\\train\",\n",
    "    transforms=get_transforms(),\n",
    ")\n",
    "val_dataset = CustomDataset(\n",
    "    image_dir=r\"rcnn_train\\dataset_rcnn\\images\\val\",\n",
    "    label_dir=r\"rcnn_train\\dataset_rcnn\\labels\\val\",\n",
    "    transforms=get_transforms(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06ba18b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda x: tuple(zip(*x)),\n",
    "    pin_memory=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda x: tuple(zip(*x)),\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b9f141a-dc16-46cd-b735-38b3241b3062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Faster R-CNN with ResNet-50 backbone\n",
    "def get_model(num_classes,checkpoint_path):\n",
    "    # Load pre-trained Faster R-CNN\n",
    "    # model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_fpn(pretrained=True)\n",
    "    \n",
    "    # Get the number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    \n",
    "    # Replace the pre-trained head with a new one for the specified number of classes\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    \n",
    "    # Optionally load weights from a checkpoint\n",
    "    if checkpoint_path:\n",
    "        state_dict = torch.load(checkpoint_path)\n",
    "        model.load_state_dict(state_dict)\n",
    "        print(f\"Model weights loaded from {checkpoint_path}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b8f9e2-e284-490b-9d0c-fe9ef564e7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "num_classes = 3 # Background + rocks,shadow\n",
    "checkpoint_path=''\n",
    "# checkpoint_path=r'rcnn_train\\models\\fasterrcnn_resnet50_epoch_5.pth'\n",
    "model = get_model(num_classes,checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "64b71051-288b-455c-85a5-8c8454390488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model to GPU if available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Define optimizer and learning rate scheduler\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.002, momentum=0.9, weight_decay=0.0002)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc561163-c6e9-4899-9f4a-a6a8702364f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train_one_epoch(model, optimizer, data_loader, device, epoch):\n",
    "    model.train()\n",
    "\n",
    "    print(f\"Starting training for Epoch {epoch}...\")\n",
    "    start_time = time.time()\n",
    "    total_batches = len(data_loader)\n",
    "\n",
    "    # Initialize variables to track time\n",
    "    batch_times = []\n",
    "\n",
    "    for batch_idx, (images, targets) in enumerate(data_loader):\n",
    "        batch_start_time = time.time()\n",
    "        \n",
    "        # Move images to the device\n",
    "        images = [img.to(device) for img in images]\n",
    "\n",
    "        # Validate and process targets\n",
    "        processed_targets = []\n",
    "        valid_images = []\n",
    "\n",
    "        for i, target in enumerate(targets):\n",
    "            # Extract bounding boxes and labels\n",
    "            boxes = target[\"boxes\"]  # Already in [x_min, y_min, x_max, y_max] format\n",
    "            labels = target[\"labels\"]\n",
    "\n",
    "            # Filter valid boxes where width and height are positive\n",
    "            valid_boxes = []\n",
    "            valid_labels = []\n",
    "\n",
    "            for box, label in zip(boxes, labels):\n",
    "                x_min, y_min, x_max, y_max = box\n",
    "                if x_max > x_min and y_max > y_min:  # Ensure positive width and height\n",
    "                    valid_boxes.append([x_min, y_min, x_max, y_max])\n",
    "                    valid_labels.append(label)\n",
    "\n",
    "            # Only add valid boxes and labels to processed targets\n",
    "            if valid_boxes:\n",
    "                processed_target = {\n",
    "                    \"boxes\": torch.tensor(valid_boxes, dtype=torch.float32).to(device),\n",
    "                    \"labels\": torch.tensor(valid_labels, dtype=torch.int64).to(device),\n",
    "                }\n",
    "                processed_targets.append(processed_target)\n",
    "                valid_images.append(images[i])  # Add corresponding valid image\n",
    "\n",
    "        # Skip iteration if no valid targets\n",
    "        if not processed_targets:\n",
    "            continue\n",
    "\n",
    "        # Ensure images and targets are aligned\n",
    "        images = valid_images\n",
    "\n",
    "        # Forward pass\n",
    "        loss_dict = model(images, processed_targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Record batch time\n",
    "        batch_time = time.time() - batch_start_time\n",
    "        batch_times.append(batch_time)\n",
    "\n",
    "        # Estimate time left\n",
    "        avg_batch_time = sum(batch_times) / len(batch_times)\n",
    "        batches_left = total_batches - (batch_idx + 1)\n",
    "        time_left = avg_batch_time * batches_left\n",
    "\n",
    "        # Log information\n",
    "        print(\n",
    "            f\"Epoch [{epoch}] | Batch [{batch_idx + 1}/{total_batches}] | \"\n",
    "            f\"Loss: {losses.item():.4f} | Batch Time: {batch_time:.2f}s | Time Left: {time_left:.2f}s\"\n",
    "        )\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"Epoch [{epoch}] completed in {total_time:.2f}s with final Loss: {losses.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc20ce0-c7e1-485f-bd54-09da71fa20b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    train_one_epoch(model, optimizer, train_loader, device, epoch)\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    # Save the model's state dictionary after every epoch\n",
    "    model_path = f\"rcnn_train\\models\\fasterrcnn_resnet50_epoch_{epoch +1}.pth\"\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Model saved: {model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f3335f-1e27-472b-aa78-bb8006abab92",
   "metadata": {},
   "source": [
    "Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02867f6c-8eda-4cd5-b572-74fcd435cf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torchvision.transforms import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Load Faster R-CNN with ResNet-50 backbone\n",
    "def get_model(num_classes):\n",
    "    # Load pre-trained Faster R-CNN\n",
    "    model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_fpn(pretrained=True)\n",
    "    # Get the number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # Replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "num_classes = 3  # Background + rock+shadow\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "\n",
    "# Load the trained model\n",
    "model = get_model(num_classes)\n",
    "model.load_state_dict(torch.load(\"rcnn_train\\models\\fasterrcnn_resnet50_epoch_5.pth\"))\n",
    "model.to(device)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "\n",
    "def prepare_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")  # Open image\n",
    "    image_tensor = F.to_tensor(image).unsqueeze(0)  # Convert image to tensor and add batch dimension\n",
    "    # image_tensor = image_tensor[0]  # Shape becomes [C, H, W]\n",
    "\n",
    "    # # Permute dimensions to [H, W, C] for displaying\n",
    "    # image_to_display = image_tensor.permute(1, 2, 0).numpy()\n",
    "\n",
    "    # # Display the image using matplotlib\n",
    "    # plt.imshow(image_to_display)\n",
    "    # plt.axis('off')  # Hide axes for better visualization\n",
    "    # plt.show()      \n",
    "    return image_tensor.to(device)\n",
    "\n",
    "\n",
    "# Load the unseen image\n",
    "# image_path = r\"C:\\Users\\Samarth\\Desktop\\polar3D\\rcnn\\dataset\\images\\train\\01_A_off_30_R_0256.png\"\n",
    "image_path = \"\"\n",
    "image_tensor = prepare_image(image_path)\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation for inference\n",
    "    prediction = model(image_tensor)\n",
    "print(prediction)\n",
    "\n",
    "# `prediction` contains:\n",
    "# - boxes: predicted bounding boxes\n",
    "# - labels: predicted class labels\n",
    "# - scores: predicted scores for each box (confidence level)\n",
    "COCO_CLASSES = {0: \"background\", 1: \"rock\", 2: \"shadow\"}\n",
    "\n",
    "def get_class_name(class_id):\n",
    "    return COCO_CLASSES.get(class_id, \"Unknown\")\n",
    "    \n",
    "# Draw bounding boxes with the correct class names and increase image size\n",
    "def draw_boxes(image, prediction, fig_size=(10, 10)):\n",
    "    boxes = prediction[0]['boxes'].cpu().numpy()  # Get predicted bounding boxes\n",
    "    labels = prediction[0]['labels'].cpu().numpy()  # Get predicted labels\n",
    "    scores = prediction[0]['scores'].cpu().numpy()  # Get predicted scores\n",
    "    \n",
    "    # Set a threshold for showing boxes (e.g., score > 0.5)\n",
    "    threshold = 0.5\n",
    "    \n",
    "    # Set up the figure size to control the image size\n",
    "    plt.figure(figsize=fig_size)  # Adjust the figure size here\n",
    "\n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        if score > threshold and label==1:\n",
    "            x_min, y_min, x_max, y_max = box\n",
    "            class_name = get_class_name(label)  # Get the class name\n",
    "            plt.imshow(image)  # Display the image\n",
    "            plt.gca().add_patch(plt.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, \n",
    "                                              linewidth=2, edgecolor='r', facecolor='none'))\n",
    "            plt.text(x_min, y_min, f\"{class_name} ({score:.2f})\", color='r')\n",
    "    \n",
    "    plt.axis('off')  # Turn off axis\n",
    "    plt.show()\n",
    "\n",
    "# Display the image with bounding boxes and correct labels\n",
    "draw_boxes(Image.open(image_path), prediction, fig_size=(12, 10))  # Example of increased size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231a65af-e139-4f49-b252-077473fb6a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b476de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.transforms import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Load Faster R-CNN with ResNet-50 backbone\n",
    "def get_model(num_classes):\n",
    "    # Load pre-trained Faster R-CNN\n",
    "    model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_fpn(pretrained=True)\n",
    "    # Get the number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # Replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "# Initialize the model\n",
    "num_classes = 3  # Background + rock + shadow\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Load the trained model\n",
    "model = get_model(num_classes)\n",
    "model.load_state_dict(torch.load(r\"C:\\Users\\Samarth\\Desktop\\polar3D\\rcnn\\models1\\fasterrcnn_resnet50_epoch_19.pth\"))\n",
    "model.to(device)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "def prepare_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")  # Open image\n",
    "    image_tensor = F.to_tensor(image).unsqueeze(0)  # Convert image to tensor and add batch dimension\n",
    "    return image_tensor.to(device)\n",
    "\n",
    "def process_random_images(img_dir, num_images=10):\n",
    "    try:\n",
    "        # Get all image files from the directory\n",
    "        image_files = [f for f in os.listdir(img_dir) if f.lower().endswith(\".png\")]\n",
    "\n",
    "        if len(image_files) < num_images:\n",
    "            raise ValueError(\n",
    "                f\"Not enough images in the directory to select {num_images}. Found only {len(image_files)}.\"\n",
    "            )\n",
    "\n",
    "        # Select random images\n",
    "        selected_images = random.sample(image_files, num_images)\n",
    "\n",
    "        # Process each selected image\n",
    "        processed_images = []\n",
    "        for image_name in selected_images:\n",
    "            image_path = os.path.join(img_dir, image_name)\n",
    "            print(f\"Processing image: {image_name}\")\n",
    "            processed_image = prepare_image(image_path)\n",
    "            if processed_image is not None:\n",
    "                processed_images.append((image_name, processed_image))\n",
    "            else:\n",
    "                print(f\"Failed to process image: {image_name}\")\n",
    "\n",
    "        return processed_images\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return []\n",
    "\n",
    "# Load and process unseen images\n",
    "# image_dir = r\"C:\\Users\\Samarth\\Desktop\\polar3D\\rcnn\\dataset\\images\\test\"\n",
    "# result_dir = r\"C:\\Users\\Samarth\\Desktop\\polar3D\\results\\rcnn\\images\"\n",
    "image_dir = \"\"\n",
    "result_dir = \"\"\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "processed_images = process_random_images(image_dir, num_images=10)\n",
    "\n",
    "for image_name, image_tensor in processed_images:\n",
    "    # Convert tensor to NumPy array for OpenCV\n",
    "    image_np = image_tensor.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "    image_np = (image_np * 255).astype(np.uint8)  # Rescale to [0, 255]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        prediction = model(image_tensor)\n",
    "\n",
    "    boxes = prediction[0]['boxes'].cpu().numpy()\n",
    "    labels = prediction[0]['labels'].cpu().numpy()\n",
    "    scores = prediction[0]['scores'].cpu().numpy()\n",
    "\n",
    "    rock_count = 0\n",
    "    label_name = image_name.replace(\"png\", \"txt\")\n",
    "    output_label_path = os.path.join(result_dir, label_name)\n",
    "\n",
    "    with open(output_label_path, 'w') as file:\n",
    "        for box, label, score in zip(boxes, labels, scores):\n",
    "            x_min, y_min, x_max, y_max = box\n",
    "            x1, y1 = int(x_min), int(y_min)\n",
    "            x2, y2 = int(x_max), int(y_max)\n",
    "            class_name = get_class_name(label)\n",
    "            \n",
    "            if score > 0.5:  # Only include confident predictions\n",
    "                file.write(f\"{class_name} {x_min:.6f} {y_min:.6f} {x_max:.6f} {y_max:.6f}\\n\")\n",
    "                \n",
    "                if label == 1:  # Count rocks\n",
    "                    rock_count += 1\n",
    "                    cv2.rectangle(image_np, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                    cv2.putText(\n",
    "                        image_np,\n",
    "                        class_name,\n",
    "                        (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.5,\n",
    "                        (255, 0, 0),\n",
    "                        2,\n",
    "                    )\n",
    "\n",
    "cv2.putText(\n",
    "    image_np,\n",
    "    f\"Total Count: {rock_count}\",\n",
    "    (10, 30),\n",
    "    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "    1,\n",
    "    (255, 0, 0),\n",
    "    2,\n",
    ")\n",
    "\n",
    "output_image_path = os.path.join(result_dir, image_name)\n",
    "cv2.imwrite(output_image_path, image_np)\n",
    "\n",
    "print(f\"YOLO labels saved to: {output_label_path}\")\n",
    "print(f\"Image with bounding boxes saved to: {output_image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799be8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.transforms import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Load Faster R-CNN with ResNet-50 backbone\n",
    "def get_model(num_classes):\n",
    "    model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_fpn(pretrained=True)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "# Initialize the model\n",
    "num_classes = 3  # Background + rock + shadow\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Load the trained model\n",
    "model = get_model(num_classes)\n",
    "model.load_state_dict(torch.load(r\"C:\\Users\\Samarth\\Desktop\\polar3D\\rcnn\\models2\\fasterrcnn_resnet50_epoch_5.pth\"))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Prepare an image\n",
    "def prepare_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image_tensor = F.to_tensor(image).unsqueeze(0)  # Convert to tensor and add batch dimension\n",
    "    return image_tensor.to(device)\n",
    "\n",
    "# Define COCO_CLASSES\n",
    "COCO_CLASSES = {0: \"background\", 1: \"rock\", 2: \"shadow\"}\n",
    "\n",
    "# Get class name\n",
    "def get_class_name(class_id):\n",
    "    return COCO_CLASSES.get(class_id, \"Unknown\")\n",
    "\n",
    "# Draw bounding boxes and save images and labels\n",
    "def draw_and_save_boxes(image, prediction, output_image_path, output_label_path, threshold=0.5):\n",
    "    boxes = prediction[0]['boxes'].cpu().numpy()\n",
    "    labels = prediction[0]['labels'].cpu().numpy()\n",
    "    scores = prediction[0]['scores'].cpu().numpy()\n",
    "\n",
    "    # Save image with bounding boxes\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.imshow(image)\n",
    "    ax = plt.gca()\n",
    "\n",
    "    label_data = []\n",
    "    rock_count = 0\n",
    "\n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        if score > threshold:\n",
    "            x_min, y_min, x_max, y_max = box\n",
    "            class_name = get_class_name(label)\n",
    "            label_data.append({\"class\": label, \"score\": score, \"bbox\": [x_min, y_min, x_max, y_max]})\n",
    "\n",
    "        if score > threshold and label==1:\n",
    "            x_min, y_min, x_max, y_max = box\n",
    "            class_name = get_class_name(label)\n",
    "            ax.add_patch(plt.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, \n",
    "                                       linewidth=2, edgecolor='r', facecolor='none'))\n",
    "            ax.text(x_min, y_min, f\"{class_name} ({score:.2f})\", color='r', fontsize=12)\n",
    "            if class_name == \"rock\":\n",
    "                rock_count += 1\n",
    "\n",
    "    ax.text(10, 10, f\"Total Rocks: {rock_count}\", color='white', fontsize=16, bbox=dict(facecolor='red', alpha=0.5))\n",
    "    plt.axis('off')\n",
    "    plt.savefig(output_image_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Save label data\n",
    "    with open(output_label_path, 'w') as f:\n",
    "        for entry in label_data:\n",
    "            f.write(f\"{entry['class']} {entry['bbox']}\\n\")\n",
    "\n",
    "# Process random images from a directory\n",
    "def process_images(input_dir, output_dir, num_images):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    image_paths = [os.path.join(input_dir, file) for file in os.listdir(input_dir) if file.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    # selected_images = random.sample(image_paths, min(num_images, len(image_paths)))\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        image_name = os.path.basename(image_path)\n",
    "        output_image_path = os.path.join(output_dir, f\"{os.path.splitext(image_name)[0]}_result.png\")\n",
    "        output_label_path = os.path.join(output_dir, f\"{os.path.splitext(image_name)[0]}_labels.txt\")\n",
    "\n",
    "        image_tensor = prepare_image(image_path)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            prediction = model(image_tensor)\n",
    "\n",
    "        draw_and_save_boxes(Image.open(image_path), prediction, output_image_path, output_label_path)\n",
    "\n",
    "# Input and output directories\n",
    "input_dir = r\"C:\\Users\\Samarth\\Desktop\\polar3D\\dataset_resized1_copy\\images\\test\"\n",
    "output_dir = r\"C:\\Users\\Samarth\\Desktop\\polar3D\\results\\rcnn\\images\"\n",
    "\n",
    "# Process 10 random images\n",
    "process_images(input_dir, output_dir, num_images=len(input_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b97ff97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2acc36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b75041a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1437e644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d1abbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
