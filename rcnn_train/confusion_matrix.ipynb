{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samarth\\AppData\\Local\\Temp\\ipykernel_25224\\1670186264.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved in C:\\Users\\Samarth\\Desktop\\polar3D\\rcnn\\predictions\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torchvision.transforms import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def load_model(model_path, device):\n",
    "    num_classes = 3  # Background + rock+shadow\n",
    "\n",
    "    # Move model to GPU if available\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "\n",
    "    # Load the trained model\n",
    "    model = get_model(num_classes)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(device)\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    return model\n",
    "\n",
    "def get_model(num_classes):\n",
    "    # Load pre-trained Faster R-CNN\n",
    "    model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_fpn(pretrained=True)\n",
    "    # Get the number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # Replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")  # Open image\n",
    "    image_tensor = F.to_tensor(image).unsqueeze(0)  # Convert image to tensor and add batch dimension\n",
    "    # image_tensor = image_tensor[0]  # Shape becomes [C, H, W]\n",
    "\n",
    "    # # Permute dimensions to [H, W, C] for displaying\n",
    "    # image_to_display = image_tensor.permute(1, 2, 0).numpy()\n",
    "\n",
    "    # # Display the image using matplotlib\n",
    "    # plt.imshow(image_to_display)\n",
    "    # plt.axis('off')  # Hide axes for better visualization\n",
    "    # plt.show()      \n",
    "    return image_tensor.to(device)\n",
    "\n",
    "def save_predictions(predictions, output_path, confidence_threshold=0.5):\n",
    "    \"\"\"Save predictions to a file.\"\"\"\n",
    "    with open(output_path, 'w') as f:\n",
    "        for box, label, score in zip(predictions[0]['boxes'], predictions[0]['labels'], predictions[0]['scores']):\n",
    "            if score >= confidence_threshold:\n",
    "                x_min, y_min, x_max, y_max = box.tolist()\n",
    "                f.write(f\"{label} {x_min} {y_min} {x_max} {y_max}\\n\")\n",
    "\n",
    "def create_predictions_dir(images_dir, model, output_dir, confidence_threshold=0.5, device='cpu'):\n",
    "    \"\"\"Generate predictions for all images in the directory.\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    image_files = [f for f in os.listdir(images_dir) if f.lower().endswith(('png', 'jpg', 'jpeg'))]\n",
    "\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(images_dir, image_file)\n",
    "        output_path = os.path.join(output_dir, os.path.splitext(image_file)[0] + '.txt')\n",
    "\n",
    "        image = preprocess_image(image_path).to(device)\n",
    "        with torch.no_grad():\n",
    "            predictions = model(image)\n",
    "\n",
    "        save_predictions(predictions, output_path, confidence_threshold)\n",
    "\n",
    "# Example usage\n",
    "model_path = \"rcnn_train\\models\\fasterrcnn_resnet50_epoch_5.pth\"  # Path to your trained Faster R-CNN model\n",
    "images_dir = \"rcnn_train\\dataset_rcnn\\images\\test\"               # Directory containing input images\n",
    "output_dir = \"rcnn_train\\predictions\"          # Directory to save prediction files\n",
    "confidence_threshold = 0.5           # Minimum confidence score for predictions\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = load_model(model_path, device)\n",
    "create_predictions_dir(images_dir, model, output_dir, confidence_threshold, device)\n",
    "\n",
    "print(f\"Predictions saved in {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizations saved in: C:\\Users\\Samarth\\Desktop\\polar3D\\rcnn\\visualizations\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "def load_labels(file_path):\n",
    "    \"\"\"Load labels from a text file.\"\"\"\n",
    "    labels = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            labels.append((int(parts[0]), float(parts[1]), float(parts[2]), float(parts[3]), float(parts[4])))\n",
    "    return labels\n",
    "\n",
    "def iou(box1, box2):\n",
    "    \"\"\"Compute IoU between two bounding boxes.\"\"\"\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "    inter_area = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    return inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "def compute_confusion_matrix(ground_truth_dir, prediction_dir, labels, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Compute confusion matrix for object detection.\n",
    "    - ground_truth_dir: Directory containing ground truth label files.\n",
    "    - prediction_dir: Directory containing prediction label files.\n",
    "    - labels: List of class labels.\n",
    "    - iou_threshold: IoU threshold for matching.\n",
    "    \"\"\"\n",
    "    confusion_matrix = np.zeros((len(labels), len(labels)), dtype=int)\n",
    "\n",
    "    gt_files = sorted(os.listdir(ground_truth_dir))\n",
    "    pred_files = sorted(os.listdir(prediction_dir))\n",
    "\n",
    "    for gt_file, pred_file in zip(gt_files, pred_files):\n",
    "        gt_path = os.path.join(ground_truth_dir, gt_file)\n",
    "        pred_path = os.path.join(prediction_dir, pred_file)\n",
    "\n",
    "        ground_truths = load_labels(gt_path)\n",
    "        predictions = load_labels(pred_path)\n",
    "\n",
    "        for gt in ground_truths:\n",
    "            gt_matched = False\n",
    "            gt_class, gt_box = gt[0], gt[1:]\n",
    "            \n",
    "            for pred in predictions:\n",
    "                pred_class, pred_box = pred[0], pred[1:]\n",
    "                if iou(gt_box, pred_box) >= iou_threshold:\n",
    "                    if pred_class == gt_class:\n",
    "                        confusion_matrix[gt_class, pred_class] += 1  # True Positive\n",
    "                    else:\n",
    "                        confusion_matrix[gt_class, pred_class] += 1  # Misclassified\n",
    "                    gt_matched = True\n",
    "                    predictions.remove(pred)  # Remove matched prediction\n",
    "                    break\n",
    "            \n",
    "            if not gt_matched:\n",
    "                confusion_matrix[gt_class, gt_class] += 1  # False Negative\n",
    "        \n",
    "        # Remaining predictions are False Positives\n",
    "        for pred in predictions:\n",
    "            pred_class = pred[0]\n",
    "            confusion_matrix[0, pred_class] += 1  # Assume unmatched predictions are background FP\n",
    "\n",
    "    return confusion_matrix\n",
    "\n",
    "def calculate_metrics(confusion_matrix):\n",
    "    \"\"\"Calculate precision, recall, and accuracy from the confusion matrix.\"\"\"\n",
    "    tp = np.diag(confusion_matrix)\n",
    "    precision = np.divide(tp, np.sum(confusion_matrix, axis=0), out=np.zeros_like(tp, dtype=float), where=np.sum(confusion_matrix, axis=0) != 0)\n",
    "    recall = np.divide(tp, np.sum(confusion_matrix, axis=1), out=np.zeros_like(tp, dtype=float), where=np.sum(confusion_matrix, axis=1) != 0)\n",
    "    accuracy = np.sum(tp) / np.sum(confusion_matrix) if np.sum(confusion_matrix) > 0 else 0\n",
    "    f1_score = np.divide(2 * (precision * recall), (precision + recall), out=np.zeros_like(precision, dtype=float), where=(precision + recall) != 0)\n",
    "\n",
    "    return precision, recall, f1_score, accuracy\n",
    "\n",
    "\n",
    "def visualize_confusion_matrix(confusion_matrix, labels, output_path):\n",
    "    \"\"\"Visualize and save the confusion matrix.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix, display_labels=labels)\n",
    "    disp.plot(cmap=plt.cm.Blues, ax=ax, colorbar=True)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "def visualize_metrics(metrics, labels, output_dir):\n",
    "    \"\"\"Visualize precision, recall, and accuracy.\"\"\"\n",
    "    precision, recall, f1_score, accuracy = metrics\n",
    "    metrics_dict = {\"Precision\": precision, \"Recall\": recall, \"F1-Score\": f1_score}\n",
    "\n",
    "    for metric_name, metric_values in metrics_dict.items():\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.bar(labels, metric_values, color=\"skyblue\")\n",
    "        plt.title(f\"{metric_name} by Class\")\n",
    "        plt.xlabel(\"Class Labels\")\n",
    "        plt.ylabel(metric_name)\n",
    "        for i, value in enumerate(metric_values):\n",
    "            plt.text(i, value + 0.01, f\"{value:.2f}\", ha=\"center\")\n",
    "        output_path = os.path.join(output_dir, f\"{metric_name.lower()}_by_class.jpeg\")\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "\n",
    "    # Visualize overall accuracy\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar([\"Overall Accuracy\"], [accuracy], color=\"lightcoral\")\n",
    "    plt.title(\"Overall Accuracy\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.text(0, accuracy + 0.01, f\"{accuracy:.2f}\", ha=\"center\")\n",
    "    output_path = os.path.join(output_dir, \"overall_accuracy.jpeg\")\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "# Example usage\n",
    "ground_truth_dir = r\"rcnn_train\\dataset_rcnn\\labels\\test\"  # Directory containing ground truth files\n",
    "prediction_dir = r\"rcnn_train\\predictions\"    # Directory containing prediction files\n",
    "labels = [\"Background\", \"Rock\", \"Shadow\"]\n",
    "\n",
    "conf_matrix = compute_confusion_matrix(ground_truth_dir, prediction_dir, labels)\n",
    "metrics = calculate_metrics(conf_matrix)\n",
    "\n",
    "output_dir = r\"C:\\Users\\Samarth\\Desktop\\polar3D\\rcnn\\visualizations\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "visualize_confusion_matrix(conf_matrix, labels, os.path.join(output_dir, \"confusion_matrix.jpeg\"))\n",
    "visualize_metrics(metrics, labels, output_dir)\n",
    "\n",
    "print(\"Visualizations saved in:\", output_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
